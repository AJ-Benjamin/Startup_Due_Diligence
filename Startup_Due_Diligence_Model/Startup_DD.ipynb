{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7c1bf0-a22d-450f-b99d-d7d12355b42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first frontier model I designed is a helpful assistant powered by the OpenAI  gpt-4o-mini. With interactive textbox to receive user input message and a clear and submit button to erase or let her get to work. Thanks @gradio. I tested by asking \"How can I be rich?\" and she delivered. \\n\\nI redesigned the frontier model but powered by Anthropic claude-3-haiku-2022… model.\\n\\nBut, what about a model but you get to choose who runs it, OpenAI or Claude? And I created it\\n\\nFinally, to create a likely to-be-used model, I created a model that\\nanalyzes the contents of a company website landing page and creates a short brochure about the company for prospective customers, investors and recruits. \\n\\nThis was achieved through web scrapping by using @beautiful soup and slapping in our frontier model with Gradio UI which have a GPT/Claude download to select who analyze the content of the website.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The first frontier model I designed is a helpful assistant powered by the OpenAI  gpt-4o-mini. With interactive textbox to receive user input message and a clear and submit button to erase or let her get to work. Thanks @gradio. I tested by asking \"How can I be rich?\" and she delivered. \n",
    "\n",
    "I redesigned the frontier model but powered by Anthropic claude-3-haiku-2022… model.\n",
    "\n",
    "But, what about a model but you get to choose who runs it, OpenAI or Claude? And I created it\n",
    "\n",
    "Finally, to create a likely to-be-used model, I created a model that\n",
    "analyzes the contents of a company website landing page and creates a short brochure about the company for prospective customers, investors and recruits. \n",
    "\n",
    "This was achieved through web scrapping by using @beautiful soup and slapping in our frontier model with Gradio UI which have a GPT/Claude download to select who analyze the content of the website.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "783c5f0e-c7d0-4e1f-ade5-9a8a7d16025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f751b336-1ea4-4701-9596-e6daf9bfe49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file callled .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Connect to OpenAI, Anthropic and Google\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7162b1c6-e34c-46b7-8b10-a8661ad3c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that analyzes the contents of a company website landing page and creates a short brochure about the company for prospective customers, investors and recruit do their due diligence on any company to know if it is a good fit for them to work with or invest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "957896b2-dd19-433f-98a3-8fc5b8a87137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs only on GPT model\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e63bb01-7f1d-4f7c-9d93-5b64e7e91cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response\")],\n",
    "    flagging_mode = \"never\"\n",
    ")\n",
    "# view.launch() # uncommment this line to test the GPT part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afe2790b-fa0a-40fe-a31f-2934c9488576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs on only Claude\n",
    "\n",
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream( \n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13d64799-f1ac-4751-bba0-91e21623d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "view = gr.Interface(\n",
    "    fn=stream_claude,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "# view.launch() # uncommment this line to test the claude part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da4ed041-a281-44cc-b1f0-fcf0159caf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building a company's brochure generator\n",
    "\n",
    "# A class to represent a webpage]\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, \"html.parser\")\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57c6201a-0f20-4759-a2e7-348babd0f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c12a0a0a-1097-45f1-8a6b-a98b2dd88e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Please generate a company brochure  for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for chunk in result:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35c06c62-20f2-423c-8608-79392f6cd661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* Running on public URL: https://9f82e0d6f1d5deb309.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9f82e0d6f1d5deb309.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing age URL:\"),\n",
    "        gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\")],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(share=True, inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec62de-cf48-4425-9bd6-2e8f8949cdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
